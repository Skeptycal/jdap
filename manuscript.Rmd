---
title: Influence of journal data archiving mandates on author attitudes, experiences, and practices
author: "Heather A. Piwowar, Todd J. Vision"
csl: peerj.csl
output:
  html_document:
    css: style.css
    fig_caption: yes
    keep_md: yes
    number_sections: yes
    toc: yes
  md_document:
    variant: markdown_github
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
  word_document:
    fig_caption: yes
bibliography: input_references.bib
---

```{r, cache=FALSE, message=FALSE, echo=FALSE, warning=FALSE}
require(knitcitations)
options("citation_format" = "pandoc")
cleanbib()
bib=read.bibtex("input_references.bib")
```

# Abstract

INTRODUCTION: Some journals require that their authors share the raw data behind their analyses, but little is known about how the introduction of these mandates affects the attitudes, experiences, and behaviour of authors.

OBJECTIVE: This study measures the correlation of journal data sharing policies with the data sharing attitudes, experiences, and behaviour of authors.

METHODS: An online questionaire was sent to all corresponding authors of 48 journals in the fields of evolution, ecology, and general biology who published papers between November 2010 and March 2014. The online questionnaire was designed to measure the respondent’s practices, experiences, and opinions around public archiving of research datasets by asking about their opinion of community norms, recent behaviour with respect to a recently published paper, previous experiences with data sharing, and attitudes toward hypothetical journal policies.

RESULTS:  Survey invitations were sent out to 23,853 corresponding authors; 4,102 responded (response rate of 17%).  Twenty-one of the journals had adopted a journal sharing requirement by the time the survey was completed.  We found the introduction of a data archiving policy significantly increased the respodent's belief that data sharing was a community norm, whereas publishing date and whether the journal ever adopted a data sharing policy did not show any statistically significant effects.  In exploratory analysis, the introduction of a journal data policy was correlated with a decrease in worries about "scooping", and increased the feeling that data archiving policies was "the right thing to do."  

CONCLUSION: This study suggests that although journals may be afraid that data archiving policies will be met with resentment and a backlash from their authors, the attitudes of autohrs after policies go into effect is positive and the policies serve to increase and normalize data sharing within their disciplines.

DATA AVAILABILITY:  The data from this study is publicly available.



# Introduction

There have been previous studies of data sharing patterns, but we are not aware of any prior research that examined attitudes and experiences of authors before and after policy implementation.  

## Data archiving policies

Sharing data is a tenet of science, yet commonplace in only a few subdisciplines.  Publicly available datasets have many potential reuses.  Unfortunately, these advantages only indirectly benefit the stakeholders who bear most of the costs for sharing their datasets: the primary data-producing investigators. As a result, authors often actively or passively withhold their research datasets from other investigators  
`r citep(c(bib["blumenthal1997withhol"], bib["ochsner2008much"], bib["savage2009empiric"]))`.

Recognizing that a data sharing culture is unlikely to be achieved without policy guidance, funders and journals have begun to request and require that investigators share their research datasets with other researchers `r citep(c(bib["brown2003the-cha"], bib["enriquez2010data-ci"]))`. Funders are motivated by the promise of resource efficiency and rapid progress. The motivation for journals to act as an advocate and gatekeeper for data sharing is less straightforward. Journals seek to publish “well-written, properly formatted research that meets community standards” and in so doing have assumed monitoring tasks to “remind researchers of community expectations and enforce some behaviors seen as advantageous to the progress of science” `r citep(bib["mccain1995mandati"])`. This role has been encouraged by many letters, white-papers, and editorials in high-profile journals.

Policies should only be adopted if their benefits outweigh their costs, across the wide array of stakeholders `r citep(bib["foster2007share-a"])`. Requiring data sharing can raise controversy `r citep(c(bib["campbell2002data-wi"], bib["king1995a-revis"]))`, increase short-term system costs `r citep(bib["beagrie2009busines"])`, and possibly motivate authors to seek alternative locations for publishing.  The goal of this study is quantify the some of the short-term benefits and costs of policy adoption in the practices, attitudes, and opinions of data producing authors.

A journal policy that requires authors to share the datasets that support their results as a condition of publication may impact the practices, attitudes, and opinions of data producing authors in many ways. The most direct impact is likely a change in frequency of data sharing, and a shift to data archiving locations specified in the policy.  Early studies suggest that authors who publish in journals with data sharing policies are more likely to share their data than authors who publish similar studies in similar journals `r citep(c(bib["piwowar2008a-revie"], bib["Piwowar2011"]))`, but these investigations were correlative and did not attempt to directly measure the impact of journal policies over time.  Previous work emphasizes the importance of sharing data through best-practice archiving methods and locations.  Authors who share data upon request often discriminate against use and users `r citep(c(bib["campbell2008what-ar"], bib["reidpath2001data-sh"]))`.  The permanence of data sharing mechanisms is also a concern; email and lab-website based sharing choices have been shown to be impermanent solutions at best `r citep(c(bib["wren2008url-dec"], bib["wren2006e-mail"]))`. 

An question of particular interest is whether the adoption of data sharing mandates leads authors to perceive that it has become a community norm to share data in their field.  If so, this shift in attitude may in and of itself it may lead to more data sharing: previous research has found that scientists “look beyond their individual interests to social cues from reference groups when deciding whether to withhold or share information requested by others” `r citep(bib["haas2009to-shar"])`.  This is consistent with findings that have found a correlation between information sharing and perceived community norm of openness and sharing `r citep(c(bib["haeusslerinforma"], bib["kuo2008a-study"]))`, as well as evidence that a scientist’s sharing decisions are influenced by expectation of reciprocity `r citep(bib["gouldnertheoret"])` and that their prior experiences with sharing predicts future sharing decisions `r citep(bib["campbell2002data-sh"])`.

A few previous studies have estimated the impact of sharing data on the experiences of authors `r citep(c(bib["blumenthal2006data-wi"], bib["gleditsch2003posting"], bib["piwowar2007sharing"], bib["ventura2005"]))`, but there is much to be learned in this area to ground expectations, accurately estimate costs and benefits, and learn about ways policies could be improved to enhance positive experiences and avoid negative ones.

Journal publishers and editors may be particularly interested in whether authors start to view data sharing mandates more positively after they have experience with them.  In particular, knowing whether experience with a data sharing policy makes authors more or less likely include the existence of data sharing policies in their decisions about future publishing venues `r citep(bib["bjork2009a-metho"])` would be of great interest to journals considering the adoption of such policies.

Evaluating the impact of a journal data sharing policy on dataset reuse is also critical.  Such an evaluation would require a longer timeframe than that of the current proposal and may be felt most strongly in a different author population; we hope to pursue this area in future work.

## Policy change is a useful opportunity for policy evaluation

Several journals adopted the Joint Data Archiving Policy in early 2011, as described at http://datadryad.org/jdap.  

This was a great opportunity to study the effect of journal data sharing mandates on the attitudes, behaviour, experiences of authors to help inform future policy decisions.

The JDAP policy requires data sharing in a public archive. Early evidence suggests stronger policies are associated with a higher frequency of data sharing `r citep(c(bib["piwowar2008a-revie"], bib["Piwowar2011"]))`.  Since JDAP requires data sharing as a condition of publication, studying this policy adoption is an opportunity to possibly measure the maximum likely effect.  Also, since the adopting journals include almost all of the high-impact journals in the field of Evolutionary Science (as per the 2009 ISI JCR), it is likely that even authors who dislike the policies will continue publishing in these journals and possibly participate in our measurement of opinions.

We note that authors in evolution and ecology have been surveyed several other times to assess data sharing attitudes and experiences, but these questionnaires have not been correlated to journal policy adoption `r citep(bib["scherle2008buildin"])`.

Because measurements of actual dataset archiving behavior can be accurately measured with a retrospective analysis of research artifacts, our proposed survey does not emphasize data archiving behaviour.  Instead, the questionnaire focused on information that is difficult or impossible to collect without a timely survey of data-producing investigators.

## Rigorous research is needed into the impact of journal policies

Although some data sharing mandates appear to have achieved almost universal sharing `r citep(bib["noor2006data-sh"])`, this is not always the case `r citep(c(bib["ochsner2008much"]))`.  Several surveys have asked about author’s perceived obstacle to sharing data `r citep(c(bib["hedstrom2008researc"]))`  `r citep(c(bib["scherle2008buildin"]))`, but changes in these attitudes have not been monitored across a policy change.  To our knowledge, the impact of data sharing mandates have only been subject to one evaluation:  the editors of Physiological Genomics briefly surveyed their authors and reviewers two years after instituting a policy that required public archiving of gene expression microarray data `r citep(c(bib["ventura2005"]))`, though unfortunately no baseline measurements are available about attitudes before the policy.  Interestingly, a recent large-scale evaluation `r citep(c(bib["Piwowar2011"]))` into the prevalence of microarray data sharing found this same journal to have the highest rate of public archiving. 

Robust studies of journal policies are infrequent, even in areas beyond data sharing.  A systematic review in 2006 examined the effect of journal adoption of CONSORT requirements for standard reporting of clinical trials `r citep(bib["plint2006does-th"])`.  It found that most publications about the journal policies were editorials or letters (699 of 1129 articles about the CONSORT policy).  Of the studies, many were non-comparative (231 of 248), only a very few (12) were considered to be comparative studies with appropriate outcomes and sufficient detail, and only one study had predefined control group. The authors conclude that, “Studies evaluating the effectiveness of the CONSORT checklist are methodologically weak” `r citep(bib["plint2006does-th"])`.  This suggests that high quality evaluations are indeed rare and thus potentially valuable contributions.  

## Research questions

The specific research questions for this study include:
 
- How do authors’ attitudes, experiences, and practices around public data archiving change when the journals they publish in adopt mandatory data archiving policies?
- Are changes specific to the journals that implement the policies, or do they extend to other journals in the same subfield?
- Does publishing in a journal with a mandatory data archiving policy decrease an author's willingness to publish in a journal with a mandatory data archiving policy again?

Twelve other survey questions will allow secondary and exploratory analyses. 


# Methods

Participants were recruited from corresponding authors who publish in specific journals between November 2010 and November 2013.  The responses of authors who published in JDAP-adopting journals were then compared, over time, to the responses of authors who published in similar journals that did not adopt JDAP. 

The instrument used to collect data was an online questionnaire. The questionnaire was designed to elicit the respondent’s practices, experiences, and opinions around public archiving of research datasets by asking about their opinion of community norms, recent behaviour with respect to a recently published paper, previous experiences with data sharing, and attitudes toward hypothetical journal policies.  

## Control journals and sample size 

The study was subject to two different types of uncertainty:  uncertainty about the estimation of aggregate parameters, and also “uncertainty about the ability of the control group to reproduce the counterfactual of how the treated unit would have evolved in the absence of the treatment” (`r citep(bib["abadie2010synthet"])`. 

It was difficult to know how to conduct a formal power analysis in these conditions, so we  based our sample size decisions on the following information:

- For populating the “treatment arm,” we asked all corresponding authors of all JDAP-adopting journals.  

- For populating the “control arms,” we recognized that the uncertainty is predominantly determined by the applicability of the controls.  Little information is currently available to determine, a priori, which journals will serve as appropriate controls.  As such, we decided that surveying twice as many control journals as treatment journals was an appropriate rule of thumb.  This balanced the need to avoid overpowering the study (and thereby increasing survey-fatigue and effort) with a desire to ensure the most useful results (anticipating that unexpected future events may render some controls inappropriate during the three years of this study, as well as recognizing that the quality of inference improves as the number of available comparison units increases `r citep(bib["abadie2010synthet"])`.  

- Control journals were selected by manual selection from a set of journals identified through ISI Journal Citation report categories as well as co-citation lists.  Attempts were made to choose journals with comparable impact factors and inclination to produce quantitative datasets.

- Assuming a 20% response rate and a control arm that was twice as large as the treatment arm, we expected a maximum of 165 responses per month, or almost 6000 responses over the course of the three year study. The actual number of responses was expected to be lower than this because only invited each corresponding author the first time they published a paper.

Journal editors were informed of the survey before it began and given contact information in case they had questions, suggestions, or concerns.

## Participant recruitment

Participants were recruited from corresponding authors who published in specific journals between November 2010 and November 2013.  Specifically, email addresses were collected for papers published the previous month (or 3 previous months, for the initial month of recruitment) in each of the target journals through the ISI Web of Science.  No other identifying information (author names, article title, etc) was retained.

The email invitation included a URL where subjects could learn more about the study and then read a fact sheet, consent, and participate if they choose.  This email contained contain an “opt out” option, which will remove their address from the reminder list.  Those who did not “opt out” were contacted by email again, a week later, politely asking them to take the survey if they haven’t already.

Recruitment email lists were compared across months, and emails only sent to those who have not previously received a recruitment email to reduce survey fatigue and ill-will.

The online survey was administered through Qualtrics, hosted by the University of North Carolina.  The online questionnaire took about 10 minutes to complete.

## Analysis approach

The primary analysis was based on responses on a seven-point Likert scale asking how strongly authors believe:  “It is the community norm in my field to publicly share datasets upon study publication by archiving all datasets online, for use by anyone for any purpose.”  Our goal was to see if author's responses to this question were influenced by publishing in a journal that had implemented JDAP.

The potential effect of JDAP adoption on authors' attitudes is might be confounded by two other factors. First, groups of researchers publishing in journals which are not planning to adopt JDAP may inherently differ from groups publishing in journals which were open to adopting the JDAP. Second, attitudes regarding data archiving may improve over time for all authors, independent of journal or policy. 

In order to test the effect of policy change on attitudes while controlling for potential confounding effects, we used an ordinal logistic regression model with three predictors: (i) whether the jounal adopted JDAP _(cNonJDAPJournal)_, (ii) the date the authors published their paper _(cDate)_, and (iii) a variable indicating whether the article was published after the the journal adopted a data archiving policy _(cAfterPolicyChange)_.  Confidence intervals were obtained by profile likelihood.  If the confidence intervals do not contain $1$ for the _(cAfterPolicyChange)_ variable then the policy would have had an affect on attitudes, independent of publication date or whether the journal was the type to adopt a JDAP policy.

We further tested the policy correlation by comparing the fit of two models, one model with all three of the above variables, and one model with two variables excluding the policy change predictor (_cAfterPolicyChange_).  If, using a likelihood-ratio test, the full model was a statistically better fit than the model without the policy change variable, it would support the hypothesis that the differences in authors attitudes were related to the policy adoption.

Twelve other survey questions allowed secondary and exploratory analyses.  

# Results

## Response rate

```{r, cache=TRUE, message=FALSE, echo=FALSE, warning=FALSE}

library(plyr)
library(dplyr)
library(zoo)
library(ggplot2)
library(assertthat)
source("./src/aux_functions.R")

load("./data/derived/JDAP_Survey_Data_Tidy.rda") # loads 'd'
load("./data/derived/Journal_JDAP_Adoption_Dates.rda") # loads 'dates'
load("./data/derived/Invitations_Timing.rda") # loads 'invitation_timing'
interactive_mode <- FALSE
jdap_adoption_dates <- dates

# add the journal info to the main dataset
assert_that( all(d$journal %in% dates$journal) ) %>% invisible
d <- left_join(d, dates, by="Journal")

# # format publication and response dates
d$PublicationDate <- parse_date(d$PublicationDate) %>% as.yearmon
d$ResponseDate <- parse_date(d$ResponseDate) %>% as.yearmon

d$ResponseDate_YM <- as.yearmon(d$ResponseDate) %>% as.character
d$ResponseDate_YQ <- as.yearqtr(d$ResponseDate) %>% as.character
d$ResponseDate_Y <- strftime(d$ResponseDate, "%Y") %>% as.character

d$PublicationDate_YM <- as.yearmon(d$PublicationDate) %>% as.character
d$PublicationDate_YQ <- as.yearqtr(d$PublicationDate) %>% as.character
d$PublicationDate_Y  <- strftime(d$PublicationDate, "%Y") %>% as.character

d$PolicyStartDate <- parse_date(d$policy_start)

# determine time since JDAP introduction in the journal where the article was published
d$DaysPolicyToPublication <- difftime(d$PublicationDate, d$PolicyStartDate, units="days")
d$DaysPolicyToResponse <- difftime(d$ResponseDate, d$PolicyStartDate, units="days") 

levels_TimeClass <- c("No JDAP","Before JDAP","After JDAP") 
levels_TimeClassByYear <- c("No\nJDAP","Before\nJDAP","1st Year\nAfter\nJDAP", "1+ Year\nAfter\nJDAP") 
d$PolicyAdoptedAtPublication <- ifelse(is.na(d$DaysPolicyToPublication), levels_TimeClass[1], ifelse(d$DaysPolicyToPublication<0, levels_TimeClass[2], levels_TimeClass[3]))
d$PolicyAdoptedAtResponse <- ifelse(is.na(d$DaysPolicyToResponse), levels_TimeClass[1], ifelse(d$DaysPolicyToResponse<0, levels_TimeClass[2], levels_TimeClass[3]))

d$PolicyAdoptedAtPublicationByYears <- ifelse(is.na(d$DaysPolicyToPublication), levels_TimeClassByYear[1], ifelse(d$DaysPolicyToPublication<0, levels_TimeClassByYear[2], ifelse(d$DaysPolicyToPublication<365, levels_TimeClassByYear[3], levels_TimeClassByYear[4] )))
d$PolicyAdoptedAtResponseByYears <- ifelse(is.na(d$DaysPolicyToResponse), levels_TimeClassByYear[1], ifelse(d$DaysPolicyToResponse<0, levels_TimeClassByYear[2], ifelse(d$DaysPolicyToResponse<365, levels_TimeClassByYear[3], levels_TimeClassByYear[4] )))

# NOTE: two invitations have NA for a publication date
# subset(invitation_timing, is.na(publication_date))

invitation_timing <- subset(invitation_timing, !is.na(publication_date))
invitation_timing$PublicationDate_YQ <- as.character(invitation_timing$publication_date) %>% parse_date %>% as.yearqtr
n_invitations_by_publication <- ddply(invitation_timing, .(Date=PublicationDate_YQ), summarize, N=length(PublicationDate_YQ))
n_invitations_by_sent_month <- ddply(invitation_timing, .(Date=as.yearmon(sent_date)), summarize, N=length(PublicationDate_YQ))

# unique(d$PolicyAdoptedAtPublication)
# d$label_PolicyAdoptedAtPublication <- ordered(d$PolicyAdoptedAtPublication, levels=c("No\nJDAP", "Before\nJDAP", "After\nJDAP"))
d$label_PolicyAdoptedAtPublication <- ordered(gsub(" ","\n",d$PolicyAdoptedAtPublication), levels=gsub(" ","\n",levels_TimeClass))
d$label_PolicyAdoptedAtPublication_space <- ordered(gsub(" "," ",d$PolicyAdoptedAtPublication), levels=gsub(" "," ", levels_TimeClass))

# Note: These are very surprising responses
# d_unexpected_responses <- subset(d, label_PolicyAdoptedAtPublication==levels_TimeClassByYear[4]) %>% subset(Q_9 == "Strongly Agree")
#d_unexpected_responses$Q_9 %>% summary
#summary(as.factor(d_unexpected_responses$Journal))
#d_unexpected_responses %>% head(2)

#head(d_unexpected_responses,3)
#subset(d_unexpected_responses, )

```

The invitations were sent out monthly between February 2011 and March 2014 to a total of $`r nrow(invitation_timing)`$ authors, and $`r nrow(d)`$ responded (corresponding to a response rate of $`r round(100*nrow(d)/nrow(invitation_timing))`$\%).

|position	| number of responses	| proprotion of responses |
| ---       | ---           | --- |
|postdoc|	        1049|	0.254|
|tenured faculty|	986|	0.239|
|(blank)|	        696|	0.169|
|research staff|	470|   	0.114|
|non-tenured faculty|	463|	0.112|
|student|	        343|	0.083|
|Other (please specify)|	117|	0.028|
|Grand Total|	4124|	1|

Journal policies as of December 2014 (surveys were sent out between February 2011 and March 2014 to authors who published between November 2010 and November 2013):

|journal	| policy start	| number of responses |
| ---       | ---           | --- |
|American Naturalist|2011-01-01|115|
|Animal Behaviour||129|
|Behavioral Ecology||62|
|Behavioral Ecology and Sociobiology||78|
|Biological Conservation||134|
|Biological Journal of the Linnean Society|2011-09-03|102|
|Biology Letters|2014-10-29|80|
|BMC Biology|2014-08-19|22|
|BMC Evolutionary Biology||102|
|BMC Plant Biology||53|
|Conservation Biology||71|
|Conservation genetics||64|
|Ecological Applications|2014-01-01|115|
|Ecological Monographs|2011-01-01|25|
|Ecology||156|
|Evolution|2011-01-01|115|
|Evolutionary Applications|2011-01-01|22|
|Evolutionary Ecology||38|
|FASEB Journal||143|
|FEBBS Letters||113|
|Functional Ecology|2012-12-05|59|
|GENETICS|2010-01-01|95|
|Genome research|2008-07-06|70|
|Global Change Biology||124|
|Heredity|2011-03-01|42|
|ISME Journal||66|
|Journal of Animal Ecology|2012-12-01|68|
|Journal of Biogeography||70|
|Journal of Ecology|2013-06-03|74|
|Journal of Evolutionary Biology|2011-10-24|96|
|Journal of Experimental Biology||179|
|Journal of Experimental Botany||123|
|Journal of Heredity|2013-01-01|32|
|Journal of Molecular Evolution||23|
|Journal of Paleontology||34|
|Molecular Biology and Evolution|2010-12-31|104|
|Molecular Ecology|2011-01-01|154|
|Molecular Phylogenetics and Evolution||83|
|Nature structural & molecular biology||50|
|New Phytologist|2010-11-23|80|
|Oecologia||151|
|Oikos|2014-03-06|118|
|Paleobiology||2|
|Physiological Genomics||38|
|PLoS Biology|2014-11-14|82|
|Proceedings of the Royal Society B: Biological Sciences|2013-03-20|217|
|Systematic Biology|2010-12-31|26|
|The Plant Journal|2010-08-18|102|



## Primary analysis

### Attitudes on data sharing and data archiving norms

The questions asked about the strength of agreement/disagreement with the following statements:

* It is the community norm in my field to share, with qualified researchers, datasets that support the results of peer-reviewed research articles. Include data sharing that occurs by any mechanism (e.g. emailing datasets upon request, posting datasets to lab websites, including datasets in journal supplementary information or data repositories).
* It is the community norm in my field to publicly archive all supporting datasets online, for use by anyone for any purpose, upon publication of a peer-reviewed research article.

---

The following plots show the responses regarding the attitudes towards data sharing and archiving for participants who (i) published in journals which have note adopted the JDAP so far ('No JDAP'), (ii) published in journals which had not _yet_ adopted the JDAP before publication ('Before JDAP'), and (iii) journals which had adopted the JDAP after publication ('After JDAP).

```{r, fig.width=10, fig.height=5, echo=FALSE, warning=FALSE, message=FALSE}

library(plyr)
library(dplyr)
library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom
question_labels <- c('Q_1'='"Data sharing is a community norm."',
                     'Q_2'='"Data archiving is a community norm."')
tmp <- melt(d, measure.vars=c('Q_1','Q_2'))
tmp$variable <- as.character(tmp$variable)
tmp$variable <- ordered(nmap(tmp$variable, question_labels), levels=question_labels)
#tmp$variable <- gsub("Q_", "Question ", tmp$variable) # gsub("Q_", "Question ", tmp$variable)

p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy")
print(p)
```


According to the model estimates, the introduction of the JDAP data archiving policy significantly increases the odds of a positive response regarding *data sharing* by a factor of $1.36$ (CI=$[1.16; 1.60]$), while publishing date and whether the journal ever adopted a JDAP policy did not show any statistically significant effects.  The estimated coefficients and confidence intervals are shown below.

```{r, message=FALSE, eval=TRUE, echo=FALSE, warning=FALSE}

library(MASS)
library(zoo)
library(dplyr)
library(knitr)

d$cAfterPolicyChange <- ifelse(d$PolicyAdoptedAtPublication=="After JDAP", 1, 0)
d$cNonJDAPJournal <- ifelse(d$PolicyAdoptedAtPublication=="No JDAP", 1, 0)
d$cDate <- as.double(as.yearmon(d$PublicationDate)) %>% scale(., scale=F)

d$respQ1 <- ordered(d$Q_1, levels=rev(levels(d$Q_1)))
d$respQ2 <- ordered(d$Q_2, levels=rev(levels(d$Q_2)))

m4 <- polr(respQ1 ~ 1 + cAfterPolicyChange + cNonJDAPJournal + cDate, data=d , Hess=TRUE)
# summary(m4)
m4.nochange <- polr(respQ1 ~ 1 + cNonJDAPJournal + cDate, data=d , Hess=TRUE)
suppressMessages( ci4 <- confint(m4) )
table4 <- exp(cbind(OR = coef(m4), ci4)) %>% cbind(., t=coef(summary(m4))[1:nrow(.),'t value'])
#table4 <- cbind(lOR = coef(m4), ci4) %>% cbind(., t=coef(summary(m4))[1:nrow(.),'t value'])

m5 <- polr(respQ2 ~ 1  + cAfterPolicyChange + cNonJDAPJournal + cDate, data=d, Hess=TRUE)
m5.nochange <- polr(respQ2 ~ 1 + cNonJDAPJournal + cDate, data=d, Hess=TRUE)
# summary(m5)
suppressMessages( ci5 <- confint(m5) )
table5 <- exp(cbind(OR = coef(m5), ci5)) %>% cbind(., t=coef(summary(m5))[1:nrow(.),'t value'])

aov.m4.nochange <- anova(m4, m4.nochange)
aov.m5.nochange <- anova(m5, m5.nochange)

# aov.m5.nochange

```



```{r, message=FALSE, eval=TRUE, echo=FALSE}
options(digits=2)
```

The result of two likelihood-ratio tests supported these findings.  The first likelihood-ratio test, comparing the full three-predictor model to a reduced model _without_ the effect of policy change revealed a significantly better fit for the full model ($\chi^2(`r aov.m4.nochange[["   Df"]][2]`)=`r aov.m4.nochange[["LR stat."]][2]`$, $p<0.001$), suggesting that the date of publication and whether a journal adopted JDAP are not as important in to an author's opinion about *data sharing* the data as whether the author published after a JDAP policy was introduced. 

<!-- http://kbroman.org/knitr_knutshell/pages/figs_tables.html -->
```{r, message=FALSE, eval=TRUE, echo=FALSE}
kable(table4, digits=2)
```

We found the similar results when we looked at the author's responses to community norms about *data archiving* rather than data sharing. The following table shows the estimated coefficients and 95\%-confidence intervals (transformed to odds ratios). According to the model estimates, the introduction of the JDAP data archiving policy significantly increases the odds of a positive response regarding *data archiving* by a factor of $1.57$ (CI=$[1.33; 1.90]$).  Being a nonJDAP journal is a significant predictor in this case, though with a much lower odds ratio.  

Comparing the full three-predictor model with a reduced model _without_ the effect of policy change revealed a significantly better fit for the full model ($\chi^2(`r aov.m5.nochange[["   Df"]][2]`)=`r aov.m5.nochange[["LR stat."]][2]`$, $p<0.001$), indicating again that the policy change was a statistically significant predictor of the author's responses about data archiving attitudes.

```{r, message=FALSE, eval=TRUE, echo=FALSE}
options(digits=2)
kable(table5, digits=2)
```


## Exploratory analysis

### Data sharing and archiving behavior

<!-- Field: Q12 -->
Are all datasets associated with your (month) (year) publication in (journal) publicly available online?

```{r, fig.width=10, fig.height=5, echo=FALSE, eval=FALSE}
library(dplyr)
library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

id_vars <- c('ResponseID','PolicyAdoptedAtPublication','label_PolicyAdoptedAtPublication')
cur_d <- d[,c(id_vars,paste0('Q_6_', 1:6))]
cur_d <- melt(cur_d, id.vars=id_vars) %>% subset(value != "")
cur_d$variable <- NULL


levels <- c("ALL datasets are publicly available online","SOME but not all of the datasets are publicly available online", "NONE of the datasets are publicly available online","We did not collect any data for that publication", "I don't know", "Other (please specify)")
cur_d$value <- ordered(cur_d$value, levels=levels)

tmp <- group_by(cur_d, PolicyAdoptedAtPublication, label_PolicyAdoptedAtPublication, value) %>% dplyr::summarize(N=length(value))  %>% dplyr::mutate(N.total=sum(N), class.Proportion=N/N.total)

p <- ggplot(tmp, aes(x = label_PolicyAdoptedAtPublication, y = 100*class.Proportion, fill = value)) + geom_bar(stat = "identity")+xlab("JDAP Policy")+ylab("Proportion of responses (in %)")

p + theme_bw() 

```
  
<!-- Field: Q13 -->
IF ALL or SOME datasets associated with this paper are publicly available, where are the datasets hosted?

```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

id_vars <- c('ResponseID','PolicyAdoptedAtPublication','label_PolicyAdoptedAtPublication')
cur_d <- d[,c(id_vars,paste0('Q_7_', 1:6))]
cur_d <- melt(cur_d, id.vars=id_vars) %>% subset(value != "")
cur_d$variable <- NULL

levels <- c("Journal supplementary information", "A repository for data or research output", "A personal or lab website", "Not applicable", "The entire dataset is in the body of the paper", "Other (please specify)")
cur_d$value <- ordered(cur_d$value, levels=levels)

tmp <- group_by(cur_d, PolicyAdoptedAtPublication, label_PolicyAdoptedAtPublication, value) %>% dplyr::summarize(N=length(value))  %>% dplyr::mutate(N.total=sum(N), class.Proportion=N/N.total)

p <- ggplot(tmp, aes(x = label_PolicyAdoptedAtPublication, y = 100*class.Proportion, fill = value)) + geom_bar(stat = "identity")+xlab("JDAP Policy")+ylab("Proportion of responses (in %)")

p + theme_bw()

```

<!-- Field: Q14 -->
If NONE or only SOME of the datasets are publicly available, which of the following reflect your experience for the dataset(s) not publicly available, for this paper? Choose all that apply.

  
```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

id_vars <- c('ResponseID','PolicyAdoptedAtPublication','label_PolicyAdoptedAtPublication')
cur_d <- d[,c(id_vars,paste0('Q_8_', 1:10))]
cur_d <- melt(cur_d, id.vars=id_vars) %>% subset(value != "")
cur_d$variable <- NULL

levels <- c("The dataset has been submitted to a repository and is currently under embargo",
            "We plan to publicly archive the dataset in the future",
            "We plan to share the dataset upon request",
            "We hadn't considered publicly archiving the dataset",
            "We considered publicly archiving data and decided not to",
            "We wanted to publicly archive the data\nbut were not able to, due to resource limitations",
            "We wanted to publicly archive the data\nbut were not able to, for other reasons",           
            "We wanted to publicly archive the data\nbut were not able to, due to licencing or funder restrictions",
            "Not applicable", "Other (please specify)")
cur_d$value <- ordered(cur_d$value, levels=levels)


tmp <- group_by(cur_d, PolicyAdoptedAtPublication, label_PolicyAdoptedAtPublication, value) %>% dplyr::summarize(N=length(value))  %>% dplyr::mutate(N.total=sum(N), class.Proportion=N/N.total)

p <- ggplot(tmp, aes(x = label_PolicyAdoptedAtPublication, y = 100*class.Proportion, fill = value)) + geom_bar(stat = "identity")+xlab("JDAP Policy")+ylab("Proportion of responses (in %)")

p + theme_bw()

```
  
<!-- Field: Q11-->
To your knowledge, what are the policies of these stakeholders as they apply to online public archiving of the datasets associated with your (month) (year) publication in (journal)? Choose all that apply

```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

facet_labels <- c('Journal', 'Funder(s)', 'Employer or institution')
responses <- c("Requires online public archiving","Recommends online public archiving","Forbids online public archiving")
tmp <- melt(d, measure.vars=paste0('Q_5_', 1:3))
tmp$variable <- facet_labels[gsub("Q_", "", tmp$variable) %>% gsub("5_", "", .) %>% as.integer]
tmp$variable <- factor(tmp$variable, levels=facet_labels)

p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="Recommends online public archiving", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
#p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```
  
### Data archiving history

<!-- Field: Q7 -->
Do any of your published research papers have publicly archived datasets?

```{r, fig.width=7, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("5+ papers with archived data","2-4 papers with archived data","1 paper with archived data","No papers with archived data") # response categories from top to bottom
tmp <- melt(d, measure.vars=c('Q_3'))
tmp$variable <- gsub("Q_", "Question ", tmp$variable)
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="1 paper with archived data", na.label="No response", xlab="% Responses", ylab="JDAP Policy")
  
print(p)
```

### Experiences with consequences of data archiving

<!-- Field: Q9 -->
To your knowledge, how often have you experienced the following situations as a result of sharing the datasets behind your published research with investigators outside your research groups? Include experiences from datasets shared outside your research groups through any mechanism, including public archiving, selected distribution, or shared individually upon request (for example, in response to an email request).

 a.  I formed new collaborations <!-- Field: Q9_1 / Q_4_1 -->
	b.  I formed new collaborations that led/are leading to publications <!-- Field: Q9_2 / Q_4_2 -->
	c.  I formed new collaborations that led/are leading to grants <!-- Field: Q9_3 / Q_4_3 -->
	d.  Others have used my datasets and formally cited me <!-- Field: Q9_4 / Q_4_4 -->
	e.  Others have used my datasets but did not formally cite me <!-- Field: Q9_5 / Q_4_5 -->
	f.  Others have found errors in my research through my datasets <!-- Field: Q9_7 / Q_4_6 -->
	g.  Others misinterpreted my datasets or used them inappropriately <!-- Field: Q9_8 / Q_4_7 -->
	h.  I have had ongoing research projects scooped by another scientist <!-- Field: Q9_9 / Q_4_8 -->
	i.  I have had future research plans scooped by another scientist <!-- Field: Q9_10 / Q_4_9 -->
	j.  The ability of a junior colleague in my group (graduate student, postdoctoral fellow, or junior faculty member) to publish subsequent research has been compromised <!-- Field: Q9_11 / Q_4_10 -->
	k.  My ability to receive commercial benefit from my research has been diminished <!-- Field: Q9_12 / Q_4_11 -->
	l.  I spent a lot of money preparing data for sharing <!-- Field: Q9_13 / Q_4_12 -->
	m.  I spent a lot of time preparing data for sharing <!-- Field: Q9_14 / Q_4_13 -->
	n.  I spent a lot of time answering questions from qualified researchers about my shared data <!-- Field: Q9_15 / Q_4_14 -->
	o.  Other (please specify) <!-- Field: Q9_16 - Q9_16_TEXT / Q_4_15 - Q_4_15_TEXT -->
    p.  I spent a lot of time answering questions from unqualified researchers about my shared data <!-- Field: Q9_17 / Q_4_16 -->

<!--
  Response Options:
  1. Many times
  2. A few times
  3. Once
  4. Never
-->

Limited to people with at least one paper with archived data:

```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses_have_data <- c("5+ papers with archived data","2-4 papers with archived data","1 paper with archived data") # "No papers with archived data", response categories from top to bottom
d_with_data <- subset(d, Q_3 %in% responses_have_data)

responses <- c( "Many times","A few times","Once","Never") # response categories from top to bottom
tmp <- melt(d_with_data, measure.vars=paste0('Q_4_',1:16 ))
tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("4_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Once", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```

```{r, fig.width=10, fig.height=5, echo=FALSE, eval=FALSE}

# Everyone 
library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c( "Many times","A few times","Once","Never") # response categories from top to bottom
tmp <- melt(d, measure.vars=paste0('Q_4_',1:16 ))
tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("4_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Once", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```

```{r, fig.width=10, fig.height=5, echo=FALSE, eval=FALSE}

# For people with no archived data:

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses_have_no_data <- c("No papers with archived data") 
d_with_no_data <- subset(d, Q_3 %in% responses_have_no_data)

responses <- c( "Many times","A few times","Once","Never") # response categories from top to bottom
tmp <- melt(d_with_no_data, measure.vars=paste0('Q_4_',1:16 ))
tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("4_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Once", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```

### Attitudes on data reuse

How strongly do you disagree/agree with the following statements?

<!-- Field: Q21 -->

```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom

question_labels <- c('Q_12'='"Using datasets collected by\ninvestigators outside my research group\nis important in my research."',
                     'Q_13'='"Using datasets collected by\ninvestigators outside my research group\nis important in my teaching or other non-research projects."')
tmp <- melt(d, measure.vars=c('Q_12','Q_13'))
tmp$variable <- as.character(tmp$variable)
tmp$variable <- ordered(nmap(tmp$variable, question_labels), levels=question_labels)
#tmp$variable <- gsub("Q_", "Question ", tmp$variable) # gsub("Q_", "Question ", tmp$variable)

p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy")
print(p)


```



### Opinions about JDAP policies
The questions below refer to the Joint Data Archiving Policy.

Imagine you just found a great journal to target when submitting your next manuscript. You read the Instruction to Authors and discover the journal adheres to the Joint Data Archiving Policy (above). 

Would you seek an alternative journal?

```{r, fig.width=5, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom
question_labels <- c('Q_9'='"I would seek alternative journals\nif JDAP was introduced')
tmp <- melt(d, measure.vars=c('Q_9'))
tmp$variable <- as.character(tmp$variable)
tmp$variable <- ordered(nmap(tmp$variable, question_labels), levels=question_labels)
#tmp$variable <- gsub("Q_", "Question ", tmp$variable) # gsub("Q_", "Question ", tmp$variable)

p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy")
print(p)
```

<!-- Field: Q18 -->

Imagine you just found a great journal to target when submitting your next manuscript. You read the Instruction to Authors and discover the journal adheres to the Joint Data Archiving Policy (above). How strongly do you disagree/agree with the following statements?
How strongly do you disagree/agree with the following statements? I am worried that ...

 a.  others might do research I am currently working on  <!-- Field: Q18_1 -->
	b.  others might do research I am planning to do  <!-- Field: Q18_2 -->
	c.  others might find errors in my research  <!-- Field: Q18_3  -->
	d.  others might misinterpret my dataset or use it inappropriately  <!-- Field: Q18_4 -->
	e.  I/we might be bothered with a lot of questions by qualified people  <!-- Field: Q18_5 -->
	f.  I/we might be bothered with a lot of questions by unqualified people  <!-- Field: Q18_6 -->
	g.  I/we might not be able to find the data  <!-- Field: Q18_7 -->
	h.  it might take me/us a lot of time to find the data  <!-- Field: Q18_8 -->
	i.  it might take me/us a lot of time to format or document the data  <!-- Field: Q18_9 -->
	j.  it might take me/us a lot of time to submit the data  <!-- Field:  Q18_10-->
	k.  I might lose intellectual property or commercial opportunities  <!-- Field: Q18_11 -->


```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom

tmp <- melt(d, measure.vars=paste0('Q_10_',1:11 ))
tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("10_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```


<!-- Field: Q19 -->
Same instructions as the previous question: Imagine you just found a great journal to target when submitting your next manuscript. You read the Instruction to Authors and discover the journal adheres to the Joint Data Archiving Policy (above). How strongly do you disagree/agree with the following statements? I am pleased because...

 a.  others will build upon my work more easily  <!-- Field: Q19_1  -->
	b.  I will get more citations  <!-- Field: Q19_2  -->
	c.  I will form more collaborations  <!-- Field: Q19_3  -->
	d.  the contribution will be valued by my promotion or tenure committee  <!-- Field: Q19_4  -->
	c.  the contribution will be valued by my funders  <!-- Field: Q19_5  -->
	d.  I will be able to reuse other work more easily  <!-- Field: Q19_6  -->
	e.  I will be able to reuse other work more often  <!-- Field: Q19_7  -->
	f.  my scientific area will progress more quickly  <!-- Field: Q19_8  -->
	g.  my scientific area will develop better tools and/or training  <!-- Field: Q19_9  -->
	h.  I think it is the right thing to do  <!-- Field: Q19_10  -->


```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom

tmp <- melt(d, measure.vars=paste0('Q_11_',1:10 ))

tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("11_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```

### Free text comments

There were 356 free text comments. A few representative ones:

- You may wish to consider fields of research. In ecology I guard my data; for evolutionary studies I use online data. The fields have very different attitudes and approaches.
- In ecology, we often spend years collecting datasets that are unique.  That effort, combined with the set of ideas that led to collection of the data, should convey a large degree of 'ownership'.  
- Thanks for researching this question.  I cannot share my data...  unless someone directly requests it and guarantees shared authorship of the product.  We invested tremendous amounts of money and personal effort in collecting and grooming these data, so we need to work through all the associated papers before others have a chance.
- I think you could have more comments related to how cumbersome, time-consuming, and expensive this new requirement is to most researchers.
- Putting the data into an archive will produce additional costs. How is going to pay for it? At the moment, we are rquested to keep the data for at least 10 years, and share them with colleagues upon request. This has worked so far, and I think we should leave it at that and not use up extra money that could be better used for funding science. 
- Science is about sharing ideas and data. If we don't do this it is not science. It's pretty simple. The only question is which datasets is it worth investing effort into sharing at what level of detail and standards. This is tricky to get the balance right but this debate should not negate the premise that we're about data sharing.
- I personally find submitting your own data a bit tedious, and I would always be worried that someone would use arcane statistical models to contradict something I found, but in the end transparency is an important feature of science and it's ridiculous that we don't have to show our data.  It is absolutely the right thing to do.



# Discussion

We found that more authors believed that data sharing and data archiving were norms in their field after they published in a journal with a JDAP policy.

Data archiving policies are becoming more prevalent: seven journals announced data archiving mandates during the course of the survey (and another three journals implemented policies shortly after the suvey completed).

even so, a minority of journal policies require data sharing `r citep(c(bib["vasilevsky2017reprodu"],bib["naughton-l2016making"]))`

Journal policies do help  `r citep(c(bib["vines2013mandate"], bib["Piwowar2011"], bib["alsheikh-ali2011public"]))`, though often not sufficient to achieve data availability for the majority of studies `r citep(c(bib["Piwowar2011"], bib["alsheikh-ali2011public"], bib["roche2015public"], bib["stodden2018an-empi"], bib["naudet2018data-sh"]))`.

This suggests author personality `r citep(c(bib["linek2017data-sh"]))` or social norms `r citep(c(bib["anagnostou2015when-da"], bib["womack2015researc"]))` may play a larger factor.

Could be helpful for journals to help spread the word about worries that are unfounded.  For example, authors are worried about scooping, but it rarely happens -- almost all of an author's papers about one of their own datasets occur within two years of its collection, whereas third-party papers are still accumulating six years later `r citep(c(bib["piwowar2013data-re"]))`.  In areas where this is less true, journal policies could be modified to support it `r citep(c(bib["whitlock2016a-balan"], bib["doi:10.1002/asi.23336"]))`

Similarily, the free text comments suggested authors are concerned about the cost of data archiving.  It may help to spread the word that money research funders spend on data archiving is good return on investment in terms of research output `r citep(c(bib["piwowar2011data-ar"]))`. 

The longitudinal study nature of this study is useful -- comparing across journals is frought, as stronger data archiving policies are disproportionately found in higher impact journals `r citep(c(bib["vasilevsky2017reprodu"], bib["piwowar2008a-revie"]))`.

Our findings are consistent with previous studies that found authors were more likely to share data if they had prior experience sharing or reusing data: `r citep(c(bib["Piwowar2011"]))`.

Several recommendations have been made for journals seeking to form a data archiving policy `r citep(c(
bib["doi:10.1002/asi.23336"],
bib["van-tuyl2016water-w"],
bib["roche2014trouble"],
bib["lin2014recomme"]))`

Also work in these:
- The influence of journal submission guidelines on authors' reporting of statistics and use of open research practices: `r citep(c(bib["giofre2017the-inf"]))`
- Journal Data Sharing Policies and Statistical Reporting Inconsistencies in Psychology: `r citep(c(bib["nuijten"]))`
- 10.1371/journal.pone.0194768


Limitations of this study include:

- This study makes no attempt to understand the rigor with which data sharing is encouraged in journals beyond their written policies:  many journals without policies nonetheless expect data sharing and many with written policies fail to enforce them.
- The opinions of corresponding authors with respect to data sharing may not be typical of all authors:  a future study could be done to quantify this.
- Respondents may be reluctant to self-report when they do not share their datasets, particularly as their sense of sharing as a community norm increases, since survey respondents are often reluctant to report engaging in socially undesirable behavior.  This may take the form of non-response, or untruthful responses.
- It will be difficult or impossible to derive causality direction for an association between reported data sharing behaviour and reported perception of data sharing as a community norm.
- By only inviting authors to participate the first time they are listed as corresponding authors within our study scope, the population we are polling will shift gradually over time away from highly-prolific authors.
- Finally, this study only facilitates a relatively short-term look at policy effect:  it will likely take many more years for the effect of these policies to be fully felt.


# Data availability

- IRB (now in dropbox)
- Recruitment emails (now in dropbox)
- Journal policies (instructions to authors as of January 29, 2011): zip of html (now in dropbox)
- Survey questions (now in dropbox)
- [Survey responses](https://github.com/hpiwowar/jdap/blob/master/data/raw_data/JDAP_Survey_Data.csv)
- [Full text comments](https://github.com/hpiwowar/jdap/blob/master/data/full_text_comments.txt)
- [Contact corresponding authors scripts](https://github.com/hpiwowar/contact_corresponding)
- [Manuscript R files](https://github.com/hpiwowar/jdap)
- [News blog about the study](https://studyonimpactofjournaldatapolicies.wordpress.com/)


# Acknowlegements and Notes

We'd like to sincerely thank everyone who took the survey.

The first paragraphs of the introduction are verbatim from Piwowar, Day & Fridsma (2007); its original publication was under a CC-BY license. 

The authors finally completed the analysis and posted this preprint more than five years after the study (and Heather's postdoc) ended: better late than never.  The introduction has been only lightly revised since it was written 5 years ago; regretfully, important recent studies have no doubt been overlooked.

# Funding

This study was funded by DataONE (OCI-0830944) and Dryad (DBI-0743720). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.

```{r, fig.width=7, fig.height=5, echo=FALSE}
# JDAP Adoption Dates

library(knitr)

journals_in_dataset <- unique(d$Journal)
relevant_jdap_adoption_dates <- subset(jdap_adoption_dates, Journal %in% journals_in_dataset)

table <- relevant_jdap_adoption_dates[,c('JournalName', 'policy', 'policy_start')]
colnames(table) <- c('Journal', 'Policy', 'Adoption Date of JDAP or Equivalent Policy')
rownames(table) <- NULL
# kable(table)
```

# Bibliolography

```{r  results="asis", echo=FALSE, message=FALSE}
# bibliography(sorting='nyt')
write.bibtex(file="output_references.bib")
````
