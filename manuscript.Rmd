---
title: "Data Archiving Attitudes"
author: "Heather A. Piwowar, Todd J. Vision"
date: "March 20, 2018"
output:
  html_document:
    css: style.css
    fig_caption: yes
    keep_md: yes
    number_sections: yes
    toc: yes
  md_document:
    variant: markdown_github
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
  word_document:
    fig_caption: yes
csl: peerj.csl
bibliography: input_references.bib
---

```{r, cache=FALSE, message=FALSE, echo=FALSE, warning=FALSE}
require(knitcitations)
options("citation_format" = "pandoc")
cleanbib()
bib=read.bibtex("input_references.bib")
```

# Abstract


# Introduction

There have been previous studies of data sharing patterns, but we are not aware of any prior research that examined attitudes and experiences of authors before and after policy implementation.  

## The promise of data sharing

Sharing data is a tenet of science, yet commonplace in only a few subdisciplines.  Publicly available datasets have many potential reuses.  Unfortunately, these advantages only indirectly benefit the stakeholders who bear most of the costs for sharing their datasets: the primary data-producing investigators. As a result, authors often actively or passively withhold their research datasets from other investigators  
`r citep(c(bib["blumenthal1997withhol"], bib["ochsner2008much-ro"], bib["savage2009empiric"]))`.

## Data archiving journal policies

Recognizing that a data sharing culture is unlikely to be achieved without policy guidance, funders and journals have begun to request and require that investigators share their research datasets with other researchers `r citep(c(bib["brown2003the-cha"], bib["enriquez2010data-ci"]))`. Funders are motivated by the promise of resource efficiency and rapid progress. The motivation for journals to act as an advocate and gatekeeper for data sharing is less straightforward. Journals seek to publish “well-written, properly formatted research that meets community standards” and in so doing have assumed monitoring tasks to “remind researchers of community expectations and enforce some behaviors seen as advantageous to the progress of science” `r citep(bib["mccain1995mandati"])`. This role has been encouraged by many letters, white-papers, and editorials in high-profile journals.

Policies should only be adopted if their benefits outweigh their costs, across the wide array of stakeholders `r citep(bib["foster2007share-a"])`. Requiring data sharing can raise controversy `r citep(c(bib["campbell2002data-wi"], bib["king1995a-revis"]))`, increase short-term system costs `r citep(bib["beagrie2009busines"])`, and possibly motivate authors to seek alternative locations for publishing.  The goal of this study is quantify the some of the short-term benefits and costs of policy adoption in the practices, attitudes, and opinions of data producing authors.

A journal policy that requires authors to share the datasets that support their results as a condition of publication may impact the practices, attitudes, and opinions of data producing authors in many ways. The most direct impact is likely a change in frequency of data sharing, and a shift to data archiving locations specified in the policy.  Early studies suggest that authors who publish in journals with data sharing policies are more likely to share their data than authors who publish similar studies in similar journals `r citep(c(bib["piwowar2008a-revie"], bib["Piwowar_2011"]))`, but these investigations were correlative and did not attempt to directly measure the impact of journal policies over time.  Previous work emphasizes the importance of sharing data through best-practice archiving methods and locations.  Authors who share data upon request often discriminate against use and users `r citep(c(bib["campbell2008what-ar"], bib["reidpath2001data-sh"]))`.  The permanence of data sharing mechanisms is also a concern; email and lab-website based sharing choices have been shown to be impermanent solutions at best `r citep(c(bib["wren2008url-dec"], bib["wren2006e-mail"]))`. 

An question of particular interest is whether the adoption of data sharing mandates leads authors to perceive that it has become a community norm to share data in their field.  If so, this shift in attitude may in and of itself it may lead to more data sharing: previous research has found that scientists “look beyond their individual interests to social cues from reference groups when deciding whether to withhold or share information requested by others” `r citep(bib["haas2009to-shar"])`.  This is consistent with findings that have found a correlation between information sharing and perceived community norm of openness and sharing `r citep(c(bib["haeusslerinforma"], bib["kuo2008a-study"]))`, as well as evidence that a scientist’s sharing decisions are influenced by expectation of reciprocity `r citep(bib["gouldnertheoret"])` and that their prior experiences with sharing predicts future sharing decisions `r citep(bib["campbell2002data-sh"])`.

A few previous studies have estimated the impact of sharing data on the experiences of authors `r citep(c(bib["blumenthal2006data-wi"], bib["gleditsch2003posting"], bib["piwowar2007sharing"], bib["ventura2005mandato"]))`, but there is much to be learned in this area to ground expectations, accurately estimate costs and benefits, and learn about ways policies could be improved to enhance positive experiences and avoid negative ones.

Journal publishers and editors may be particularly interested in whether authors start to view data sharing mandates more positively after they have experience with them.  In particular, knowing whether experience with a data sharing policy makes authors more or less likely include the existence of data sharing policies in their decisions about future publishing venues `r citep(bib["bjork2009a-metho"])` would be of great interest to journals considering the adoption of such policies.

Evaluating the impact of a journal data sharing policy on dataset reuse is also critical.  Such an evaluation would require a longer timeframe than that of the current proposal and may be felt most strongly in a different author population; we hope to pursue this area in future work.

## Upcoming policy change is a useful opportunity for policy evaluation

Several journals plan to adopt the Joint Data Archiving Policy in early 2011, as described at http://datadryad.org/jdap.  

This is a great opportunity to study the effect of journal data sharing mandates on the attitudes, behaviour, experiences of authors to help inform future policy decisions.

The JDAP policy requires data sharing in a public archive. Early evidence suggests stronger policies are associated with a higher frequency of data sharing `r citep(c(bib["piwowar2008a-revie"], bib["Piwowar_2011"]))`.  Since JDAP requires data sharing as a condition of publication, studying this policy adoption is an opportunity to possibly measure the maximum likely effect.  Also, since the adopting journals include almost all of the high-impact journals in the field of Evolutionary Science (as per the 2009 ISI JCR), it is likely that even authors who dislike the policies will continue publishing in these journals and possibly participate in our measurement of opinions.

We note that authors in evolution and ecology have been surveyed several other times to assess data sharing attitudes and experiences, but these questionnaires have not been correlated to journal policy adoption `r citep(bib["scherle2008buildin"])`.

Because measurements of actual dataset archiving behavior can be accurately measured with a retrospective analysis of research artifacts, our proposed survey does not emphasize data archiving behaviour.  Instead, the questionnaire will focus on information that is difficult or impossible to collect without a timely survey of data-producing investigators.

## Rigorous research is needed into the impact of journal policies

Although some data sharing mandates appear to have achieved almost universal sharing `r citep(bib["noor2006data-sh"])`, this is not always the case `r citep(bib["ochsner2008much-ro"])`.  Several surveys have asked about author’s perceived obstacle to sharing data `r citep(c(bib["hedstrom2008researc"], bib["scherle2008buildin"]))`, but changes in these attitudes have not been monitored across a policy change.  To our knowledge, the impact of data sharing mandates have only been subject to one evaluation:  the editors of Physiological Genomics briefly surveyed their authors and reviewers two years after instituting a policy that required public archiving of gene expression microarray data `r citep(bib["ventura2005mandato"])`, though unfortunately no baseline measurements are available about attitudes before the policy.  Interestingly, a recent large-scale evaluation `r citep(bib["Piwowar_2011"])` into the prevalence of microarray data sharing found this same journal to have the highest rate of public archiving. 

Robust studies of journal policies are infrequent, even in areas beyond data sharing.  A systematic review in 2006 examined the effect of journal adoption of CONSORT requirements for standard reporting of clinical trials `r citep(bib["plint2006does-th"])`.  It found that most publications about the journal policies were editorials or letters (699 of 1129 articles about the CONSORT policy).  Of the studies, many were non-comparative (231 of 248), only a very few (12) were considered to be comparative studies with appropriate outcomes and sufficient detail, and only one study had predefined control group. The authors conclude that, “Studies evaluating the effectiveness of the CONSORT checklist are methodologically weak” `r citep(bib["plint2006does-th"])`.  This suggests that high quality evaluations are indeed rare and thus potentially valuable contributions.  

## Research questions

The specific research questions for this study include:
 
- How do authors’ attitudes, experiences, and practices around public data archiving change when the journals they publish in adopt mandatory data archiving policies?
- Are changes specific to the journals that implement the policies, or do they extend to other journals in the same subfield?
- Does publishing in a journal with a mandatory data archiving policy decrease an author's willingness to publish in a journal with a mandatory data archiving policy again?

Twelve other survey questions will allow secondary and exploratory analyses. 


# Methods

Participants were recruited from corresponding authors who publish in specific journals between November 2010 and November 2013.  The responses of authors who published in JDAP-adopting journals were then compared, over time, to the responses of authors who published in similar journals that did not adopt JDAP. 

The instrument used to collect data is be an online questionnaire. The questionnaire is designed to elicit the respondent’s practices, experiences, and opinions around public archiving of research datasets by asking about their opinion of community norms, recent behaviour with respect to a recently published paper, previous experiences with data sharing, and attitudes toward hypothetical journal policies  

## Control jounrnals and sample size 

The proposed study is subject to two different types of uncertainty:  uncertainty about the estimation of aggregate parameters, and also “uncertainty about the ability of the control group to reproduce the counterfactual of how the treated unit would have evolved in the absence of the treatment” (`r citep(bib["abadie2010synthet"])`. It was difficult to know how to conduct a formal power analysis in these conditions, so we  based our sample size decisions on the following information.

For populating the “treatment arm,” we asked all corresponding authors of all JDAP-adopting journals.  

For populating the “control arms,” we recognized that the uncertainty is predominantly determined by the applicability of the controls.  Little information is currently available to determine, a priori, which journals will serve as appropriate controls.  As such, we decided that surveying twice as many control journals as treatment journals was an appropriate rule of thumb.  This balanced the need to avoid overpowering the study (and thereby increasing survey-fatigue and effort) with a desire to ensure the most useful results (anticipating that unexpected future events may render some controls inappropriate during the three years of this study, as well as recognizing that the quality of inference improves as the number of available comparison units increases `r citep(bib["abadie2010synthet"])`.  

Control journals were selected by manual selection from a set of journals identified through ISI Journal Citation report categories as well as co-citation lists.  Attempts were made to choose journals with comparable impact factors and inclination to produce quantitative datasets.

Assuming a 20% response rate and a control arm that was twice as large as the treatment arm, we expected a maximum of 165 responses per month, or almost 6000 responses over the course of the three year study. The actual number of responses was expected to be lower than this because only invited each corresponding author the first time they published a paper.

Journal editors were informed of the survey before it began and given contact information in case they had questions, suggestions, or concerns.

## Participant recruitment

Participants were recruited from corresponding authors who published in specific journals between November 2010 and November 2013.  Specifically, email addresses were collected for papers published the previous month (or 3 previous months, for the initial month of recruitment) in each of the target journals through the ISI Web of Science.  No other identifying information (author names, article title, etc) was retained.

The email invitation included  a URL where subjects can learn more about the study and then read a fact sheet, consent, and participate if they choose.  This email contained contain an “opt out” option, which will remove their address from the reminder list.  Those who did not “opt out” were contacted by email again, a week later, politely asking them to take the survey if they haven’t already.

Recruitment email lists were compared across months, and emails only sent to those who have not previously received a recruitment email to reduce survey fatigue and ill-will.

The online survey was administered through Qualtrics, hosted by the University of North Carolina.  The online questionnaire took about 10 minutes to complete.

## Analysis 

The responses of authors who published in JDAP-adopting journals were compared, over time, to  the responses of authors who published in similar journals that did not adopt JDAP.  

The primary analysis will be a seven-point Likert scale asking how strongly authors believe:  “It is the community norm in my field to publicly share datasets upon study publication by archiving all datasets online, for use by anyone for any purpose.”  About twelve other survey questions will allow secondary and exploratory analyses.  


# Results

## Response rate

```{r, cache=TRUE, message=FALSE, echo=FALSE, warning=FALSE}

library(plyr)
library(dplyr)
library(zoo)
library(ggplot2)
library(assertthat)
source("./src/aux_functions.R")

load("./data/derived/JDAP_Survey_Data_Tidy.rda") # loads 'd'
load("./data/derived/Journal_JDAP_Adoption_Dates.rda") # loads 'dates'
load("./data/derived/Invitations_Timing.rda") # loads 'invitation_timing'
interactive_mode <- FALSE
jdap_adoption_dates <- dates

# add the journal info to the main dataset
assert_that( all(d$journal %in% dates$journal) ) %>% invisible
d <- left_join(d, dates, by="Journal")

# # format publication and response dates
d$PublicationDate <- parse_date(d$PublicationDate) %>% as.yearmon
d$ResponseDate <- parse_date(d$ResponseDate) %>% as.yearmon

d$ResponseDate_YM <- as.yearmon(d$ResponseDate) %>% as.character
d$ResponseDate_YQ <- as.yearqtr(d$ResponseDate) %>% as.character
d$ResponseDate_Y <- strftime(d$ResponseDate, "%Y") %>% as.character

d$PublicationDate_YM <- as.yearmon(d$PublicationDate) %>% as.character
d$PublicationDate_YQ <- as.yearqtr(d$PublicationDate) %>% as.character
d$PublicationDate_Y  <- strftime(d$PublicationDate, "%Y") %>% as.character

d$PolicyStartDate <- parse_date(d$policy_start)

# determine time since JDAP introduction in the journal where the article was published
d$DaysPolicyToPublication <- difftime(d$PublicationDate, d$PolicyStartDate, units="days")
d$DaysPolicyToResponse <- difftime(d$ResponseDate, d$PolicyStartDate, units="days") 

levels_TimeClass <- c("No JDAP","Before JDAP","After JDAP") 
levels_TimeClassByYear <- c("No\nJDAP","Before\nJDAP","1st Year\nAfter\nJDAP", "1+ Year\nAfter\nJDAP") 
d$PolicyAdoptedAtPublication <- ifelse(is.na(d$DaysPolicyToPublication), levels_TimeClass[1], ifelse(d$DaysPolicyToPublication<0, levels_TimeClass[2], levels_TimeClass[3]))
d$PolicyAdoptedAtResponse <- ifelse(is.na(d$DaysPolicyToResponse), levels_TimeClass[1], ifelse(d$DaysPolicyToResponse<0, levels_TimeClass[2], levels_TimeClass[3]))

d$PolicyAdoptedAtPublicationByYears <- ifelse(is.na(d$DaysPolicyToPublication), levels_TimeClassByYear[1], ifelse(d$DaysPolicyToPublication<0, levels_TimeClassByYear[2], ifelse(d$DaysPolicyToPublication<365, levels_TimeClassByYear[3], levels_TimeClassByYear[4] )))
d$PolicyAdoptedAtResponseByYears <- ifelse(is.na(d$DaysPolicyToResponse), levels_TimeClassByYear[1], ifelse(d$DaysPolicyToResponse<0, levels_TimeClassByYear[2], ifelse(d$DaysPolicyToResponse<365, levels_TimeClassByYear[3], levels_TimeClassByYear[4] )))

# NOTE: two invitations have NA for a publication date
# subset(invitation_timing, is.na(publication_date))

invitation_timing <- subset(invitation_timing, !is.na(publication_date))
invitation_timing$PublicationDate_YQ <- as.character(invitation_timing$publication_date) %>% parse_date %>% as.yearqtr
n_invitations_by_publication <- ddply(invitation_timing, .(Date=PublicationDate_YQ), summarize, N=length(PublicationDate_YQ))
n_invitations_by_sent_month <- ddply(invitation_timing, .(Date=as.yearmon(sent_date)), summarize, N=length(PublicationDate_YQ))

# unique(d$PolicyAdoptedAtPublication)
# d$label_PolicyAdoptedAtPublication <- ordered(d$PolicyAdoptedAtPublication, levels=c("No\nJDAP", "Before\nJDAP", "After\nJDAP"))
d$label_PolicyAdoptedAtPublication <- ordered(gsub(" ","\n",d$PolicyAdoptedAtPublication), levels=gsub(" ","\n",levels_TimeClass))
d$label_PolicyAdoptedAtPublication_space <- ordered(gsub(" "," ",d$PolicyAdoptedAtPublication), levels=gsub(" "," ", levels_TimeClass))

# Note: These are very surprising responses
# d_unexpected_responses <- subset(d, label_PolicyAdoptedAtPublication==levels_TimeClassByYear[4]) %>% subset(Q_9 == "Strongly Agree")
#d_unexpected_responses$Q_9 %>% summary
#summary(as.factor(d_unexpected_responses$Journal))
#d_unexpected_responses %>% head(2)

#head(d_unexpected_responses,3)
#subset(d_unexpected_responses, )

```

[TODO: LIST THE JOURNALS IN CONTROL AND JDAP ARMS]

The invitations were sent out monthly between February 2011 and March 2014 to a total of $`r nrow(invitation_timing)`$ authors, and $`r nrow(d)`$ responded (corresponding to a response rate of $`r round(100*nrow(d)/nrow(invitation_timing))`$\%).


## Primary analysis

### Attitudes on data sharing and data archiving norms

The questions asked about the strength of agreement/disagreement with the following statements:

* It is the community norm in my field to share, with qualified researchers, datasets that support the results of peer-reviewed research articles. Include data sharing that occurs by any mechanism (e.g. emailing datasets upon request, posting datasets to lab websites, including datasets in journal supplementary information or data repositories).
* It is the community norm in my field to publicly archive all supporting datasets online, for use by anyone for any purpose, upon publication of a peer-reviewed research article.

---

The following plots show the responses regarding the attitudes towards data sharing and archiving for participants who (i) published in journals which have note adopted the JDAP so far ('No JDAP'), (ii) published in journals which had not _yet_ adopted the JDAP before publication ('Before JDAP'), and (iii) journals which had adopted the JDAP before publication ('After JDAP).

```{r, fig.width=10, fig.height=5, echo=FALSE, warning=FALSE, message=FALSE}

library(plyr)
library(dplyr)
library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom
question_labels <- c('Q_1'='"Data sharing is a community norm."',
                     'Q_2'='"Data archiving is a community norm."')
tmp <- melt(d, measure.vars=c('Q_1','Q_2'))
tmp$variable <- as.character(tmp$variable)
tmp$variable <- ordered(nmap(tmp$variable, question_labels), levels=question_labels)
#tmp$variable <- gsub("Q_", "Question ", tmp$variable) # gsub("Q_", "Question ", tmp$variable)

p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy")
print(p)
```

The potential effect of JDAP adoption on authors' attitudes is might be confounded by two other factors. Firstly, groups of researchers publishing in journals which are not planning to adopt the JDAP (or at least have not done so yet) may inherently differ from groups publishing in journals which were open to adopting the JDAP. Secondly, attitudes regarding data archiving may improve over time. 

[TODO: REPHASE PARAGRAPHS BELOW]

In order to test for an effect of policy change on attitudes while controlling for potential confounding effects, we used an ordinal logistic regression model with three predictors: (i) journal type _(cNonJDAPJournal)_, (ii) (centered) publication date in years _(cDate)_, and (iii) a variable indicating whether the article was published after the the journal adopted a data archiving policy _(cAfterPolicyChange)_.


```{r, message=FALSE, eval=TRUE, echo=FALSE, warning=FALSE}

library(MASS)
library(zoo)
library(dplyr)
library(knitr)

d$cAfterPolicyChange <- ifelse(d$PolicyAdoptedAtPublication=="After JDAP", 1, 0)
d$cNonJDAPJournal <- ifelse(d$PolicyAdoptedAtPublication=="No JDAP", 1, 0)
d$cDate <- as.double(as.yearmon(d$PublicationDate)) %>% scale(., scale=F)

d$respQ1 <- ordered(d$Q_1, levels=rev(levels(d$Q_1)))
d$respQ2 <- ordered(d$Q_2, levels=rev(levels(d$Q_2)))

m4 <- polr(respQ1 ~ 1 + cAfterPolicyChange + cNonJDAPJournal + cDate, data=d , Hess=TRUE)
# summary(m4)
m4.justchange <- polr(respQ1 ~ 1 + cAfterPolicyChange, data=d , Hess=TRUE)
m4.nochange <- polr(respQ1 ~ 1 + cNonJDAPJournal + cDate, data=d , Hess=TRUE)
suppressMessages( ci4 <- confint(m4) )
table4 <- exp(cbind(OR = coef(m4), ci4)) %>% cbind(., t=coef(summary(m4))[1:nrow(.),'t value'])
#table4 <- cbind(lOR = coef(m4), ci4) %>% cbind(., t=coef(summary(m4))[1:nrow(.),'t value'])

m5 <- polr(respQ2 ~ 1  + cAfterPolicyChange + cNonJDAPJournal + cDate, data=d, Hess=TRUE)
m5.justchange <- polr(respQ2 ~ 1 + cAfterPolicyChange , data=d, Hess=TRUE)
m5.nochange <- polr(respQ2 ~ 1 + cNonJDAPJournal + cDate, data=d, Hess=TRUE)
# summary(m5)
suppressMessages( ci5 <- confint(m5) )
table5 <- exp(cbind(OR = coef(m5), ci5)) %>% cbind(., t=coef(summary(m5))[1:nrow(.),'t value'])

aov.m4.justchange <- anova(m4, m4.justchange)
aov.m4.nochange <- anova(m4, m4.nochange)
aov.m5.justchange <- anova(m5, m5.justchange)
aov.m5.nochange <- anova(m5, m5.nochange)

# aov.m5.nochange

```


The following table shows the estimated coefficients and 95\%-confidence intervals (transformed to odds ratios) for responses to *question 1*. Effects are statistically significant at the $\alpha=0.05$ level when the transformed confidence intervals do not contain $1$. Confidence intervals were obtained by profile likelihood. According to the model estimates, the introduction of the JDAP data archiving policy significantly increases the odds of a positive response regarding *data sharing* by a factor of $1.36$ (CI=$[1.16; 1.60]$), while the remaining two predictors do not show any statistically significant effects.

```{r, message=FALSE, eval=TRUE, echo=FALSE}
options(digits=2)
```

We conducted two likelihood-ratio tests to assess the effect of change in policy and the other predictors on reported attitudes. The first likelihood-ratio test, comparing the full three-predictor model with a reduced model _without_ the effect of policy change revealed a significantly better fit for the full model ($\chi^2(`r aov.m4.nochange[["   Df"]][2]`)=`r aov.m4.nochange[["LR stat."]][2]`$, $p<0.001$). A second likelihood-ratio test comparing the full model with a reduced model using _only_ the policy change predictor (_cAfterPolicyChange_) revealed no statistically significantly difference ($\chi^2(`r aov.m4.justchange[["   Df"]][2]`)=`r aov.m4.justchange[["LR stat."]][2]`$, $p=`r aov.m4.justchange[["Pr(Chi)"]][2]`$).

<!-- http://kbroman.org/knitr_knutshell/pages/figs_tables.html -->
```{r, message=FALSE, eval=TRUE, echo=FALSE}
kable(table4, digits=2)
```

Similarily, the following table shows the estimated coefficients and 95\%-confidence intervals (transformed to odds ratios) for responses to *question 2*. According to the model estimates, the introduction of the JDAP data archiving policy significantly increases the odds of a positive response regarding *data archiving* by a factor of $1.57$ (CI=$[1.33; 1.90]$), while the remaining two predictors do not show any statistically significant effects.

Here too, we conducted two likelihood-ratio tests to assess the effect of change in policy and the other predictors on reported attitudes. The first likelihood-ratio test, comparing the full three-predictor model with a reduced model _without_ the effect of policy change revealed a significantly better fit for the full model ($\chi^2(`r aov.m5.nochange[["   Df"]][2]`)=`r aov.m5.nochange[["LR stat."]][2]`$, $p<0.001$). A second likelihood-ratio test comparing the full model with a reduced model using _only_ the policy change predictor (_cAfterPolicyChange_) revealed no statistically significantly difference ($\chi^2(`r aov.m5.justchange[["   Df"]][2]`)=`r aov.m5.justchange[["LR stat."]][2]`$, $p=`r aov.m5.justchange[["Pr(Chi)"]][2]`$).

```{r, message=FALSE, eval=TRUE, echo=FALSE}
options(digits=2)
kable(table5, digits=2)
```


## Exploratory analysis

### Data sharing and archiving behavior

<!-- Field: Q12 -->
Are all datasets associated with your (month) (year) publication in (journal) publicly available online?

```{r, fig.width=10, fig.height=5, echo=FALSE, eval=FALSE}
library(dplyr)
library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

id_vars <- c('ResponseID','PolicyAdoptedAtPublication','label_PolicyAdoptedAtPublication')
cur_d <- d[,c(id_vars,paste0('Q_6_', 1:6))]
cur_d <- melt(cur_d, id.vars=id_vars) %>% subset(value != "")
cur_d$variable <- NULL


levels <- c("ALL datasets are publicly available online","SOME but not all of the datasets are publicly available online", "NONE of the datasets are publicly available online","We did not collect any data for that publication", "I don't know", "Other (please specify)")
cur_d$value <- ordered(cur_d$value, levels=levels)

tmp <- group_by(cur_d, PolicyAdoptedAtPublication, label_PolicyAdoptedAtPublication, value) %>% dplyr::summarize(N=length(value))  %>% dplyr::mutate(N.total=sum(N), class.Proportion=N/N.total)

p <- ggplot(tmp, aes(x = label_PolicyAdoptedAtPublication, y = 100*class.Proportion, fill = value)) + geom_bar(stat = "identity")+xlab("JDAP Policy")+ylab("Proportion of responses (in %)")

p + theme_bw() 

```
  
<!-- Field: Q13 -->
IF ALL or SOME datasets associated with this paper are publicly available, where are the datasets hosted?

```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

id_vars <- c('ResponseID','PolicyAdoptedAtPublication','label_PolicyAdoptedAtPublication')
cur_d <- d[,c(id_vars,paste0('Q_7_', 1:6))]
cur_d <- melt(cur_d, id.vars=id_vars) %>% subset(value != "")
cur_d$variable <- NULL

levels <- c("Journal supplementary information", "A repository for data or research output", "A personal or lab website", "Not applicable", "The entire dataset is in the body of the paper", "Other (please specify)")
cur_d$value <- ordered(cur_d$value, levels=levels)

tmp <- group_by(cur_d, PolicyAdoptedAtPublication, label_PolicyAdoptedAtPublication, value) %>% dplyr::summarize(N=length(value))  %>% dplyr::mutate(N.total=sum(N), class.Proportion=N/N.total)

p <- ggplot(tmp, aes(x = label_PolicyAdoptedAtPublication, y = 100*class.Proportion, fill = value)) + geom_bar(stat = "identity")+xlab("JDAP Policy")+ylab("Proportion of responses (in %)")

p + theme_bw()

```

<!-- Field: Q14 -->
If NONE or only SOME of the datasets are publicly available, which of the following reflect your experience for the dataset(s) not publicly available, for this paper? Choose all that apply.

  
```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

id_vars <- c('ResponseID','PolicyAdoptedAtPublication','label_PolicyAdoptedAtPublication')
cur_d <- d[,c(id_vars,paste0('Q_8_', 1:10))]
cur_d <- melt(cur_d, id.vars=id_vars) %>% subset(value != "")
cur_d$variable <- NULL

levels <- c("The dataset has been submitted to a repository and is currently under embargo",
            "We plan to publicly archive the dataset in the future",
            "We plan to share the dataset upon request",
            "We hadn't considered publicly archiving the dataset",
            "We considered publicly archiving data and decided not to",
            "We wanted to publicly archive the data\nbut were not able to, due to resource limitations",
            "We wanted to publicly archive the data\nbut were not able to, for other reasons",           
            "We wanted to publicly archive the data\nbut were not able to, due to licencing or funder restrictions",
            "Not applicable", "Other (please specify)")
cur_d$value <- ordered(cur_d$value, levels=levels)


tmp <- group_by(cur_d, PolicyAdoptedAtPublication, label_PolicyAdoptedAtPublication, value) %>% dplyr::summarize(N=length(value))  %>% dplyr::mutate(N.total=sum(N), class.Proportion=N/N.total)

p <- ggplot(tmp, aes(x = label_PolicyAdoptedAtPublication, y = 100*class.Proportion, fill = value)) + geom_bar(stat = "identity")+xlab("JDAP Policy")+ylab("Proportion of responses (in %)")

p + theme_bw()

```
  
<!-- Field: Q11-->
To your knowledge, what are the policies of these stakeholders as they apply to online public archiving of the datasets associated with your (month) (year) publication in (journal)? Choose all that apply

```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

facet_labels <- c('Journal', 'Funder(s)', 'Employer or institution')
responses <- c("Requires online public archiving","Recommends online public archiving","Forbids online public archiving")
tmp <- melt(d, measure.vars=paste0('Q_5_', 1:3))
tmp$variable <- facet_labels[gsub("Q_", "", tmp$variable) %>% gsub("5_", "", .) %>% as.integer]
tmp$variable <- factor(tmp$variable, levels=facet_labels)

p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="Recommends online public archiving", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
#p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```
  
### Data archiving history

<!-- Field: Q7 -->
Do any of your published research papers have publicly archived datasets?

```{r, fig.width=7, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("5+ papers with archived data","2-4 papers with archived data","1 paper with archived data","No papers with archived data") # response categories from top to bottom
tmp <- melt(d, measure.vars=c('Q_3'))
tmp$variable <- gsub("Q_", "Question ", tmp$variable)
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="1 paper with archived data", na.label="No response", xlab="% Responses", ylab="JDAP Policy")
  
print(p)
```

### Experiences with consequences of data archiving

<!-- Field: Q9 -->
To your knowledge, how often have you experienced the following situations as a result of sharing the datasets behind your published research with investigators outside your research groups? Include experiences from datasets shared outside your research groups through any mechanism, including public archiving, selected distribution, or shared individually upon request (for example, in response to an email request).

 a.  I formed new collaborations <!-- Field: Q9_1 / Q_4_1 -->
	b.  I formed new collaborations that led/are leading to publications <!-- Field: Q9_2 / Q_4_2 -->
	c.  I formed new collaborations that led/are leading to grants <!-- Field: Q9_3 / Q_4_3 -->
	d.  Others have used my datasets and formally cited me <!-- Field: Q9_4 / Q_4_4 -->
	e.  Others have used my datasets but did not formally cite me <!-- Field: Q9_5 / Q_4_5 -->
	f.  Others have found errors in my research through my datasets <!-- Field: Q9_7 / Q_4_6 -->
	g.  Others misinterpreted my datasets or used them inappropriately <!-- Field: Q9_8 / Q_4_7 -->
	h.  I have had ongoing research projects scooped by another scientist <!-- Field: Q9_9 / Q_4_8 -->
	i.  I have had future research plans scooped by another scientist <!-- Field: Q9_10 / Q_4_9 -->
	j.  The ability of a junior colleague in my group (graduate student, postdoctoral fellow, or junior faculty member) to publish subsequent research has been compromised <!-- Field: Q9_11 / Q_4_10 -->
	k.  My ability to receive commercial benefit from my research has been diminished <!-- Field: Q9_12 / Q_4_11 -->
	l.  I spent a lot of money preparing data for sharing <!-- Field: Q9_13 / Q_4_12 -->
	m.  I spent a lot of time preparing data for sharing <!-- Field: Q9_14 / Q_4_13 -->
	n.  I spent a lot of time answering questions from qualified researchers about my shared data <!-- Field: Q9_15 / Q_4_14 -->
	o.  Other (please specify) <!-- Field: Q9_16 - Q9_16_TEXT / Q_4_15 - Q_4_15_TEXT -->
    p.  I spent a lot of time answering questions from unqualified researchers about my shared data <!-- Field: Q9_17 / Q_4_16 -->

<!--
  Response Options:
  1. Many times
  2. A few times
  3. Once
  4. Never
-->

Limited to people with at least one paper with archived data:

```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses_have_data <- c("5+ papers with archived data","2-4 papers with archived data","1 paper with archived data") # "No papers with archived data", response categories from top to bottom
d_with_data <- subset(d, Q_3 %in% responses_have_data)

responses <- c( "Many times","A few times","Once","Never") # response categories from top to bottom
tmp <- melt(d_with_data, measure.vars=paste0('Q_4_',1:16 ))
tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("4_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Once", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```

```{r, fig.width=10, fig.height=5, echo=FALSE, eval=FALSE}

# Everyone 
library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c( "Many times","A few times","Once","Never") # response categories from top to bottom
tmp <- melt(d, measure.vars=paste0('Q_4_',1:16 ))
tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("4_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Once", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```

```{r, fig.width=10, fig.height=5, echo=FALSE, eval=FALSE}

# For people with no archived data:

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses_have_no_data <- c("No papers with archived data") 
d_with_no_data <- subset(d, Q_3 %in% responses_have_no_data)

responses <- c( "Many times","A few times","Once","Never") # response categories from top to bottom
tmp <- melt(d_with_no_data, measure.vars=paste0('Q_4_',1:16 ))
tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("4_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Once", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```

### Attitudes on data reuse

How strongly do you disagree/agree with the following statements?

<!-- Field: Q21 -->

```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom

question_labels <- c('Q_12'='"Using datasets collected by\ninvestigators outside my research group\nis important in my research."',
                     'Q_13'='"Using datasets collected by\ninvestigators outside my research group\nis important in my teaching or other non-research projects."')
tmp <- melt(d, measure.vars=c('Q_12','Q_13'))
tmp$variable <- as.character(tmp$variable)
tmp$variable <- ordered(nmap(tmp$variable, question_labels), levels=question_labels)
#tmp$variable <- gsub("Q_", "Question ", tmp$variable) # gsub("Q_", "Question ", tmp$variable)

p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy")
print(p)


```



### Opinions about JDAP policies
The questions below refer to the Joint Data Archiving Policy.

Imagine you just found a great journal to target when submitting your next manuscript. You read the Instruction to Authors and discover the journal adheres to the Joint Data Archiving Policy (above). 

Would you seek an alternative journal?

```{r, fig.width=5, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom
question_labels <- c('Q_9'='"I would seek alternative journals\nif JDAP was introduced')
tmp <- melt(d, measure.vars=c('Q_9'))
tmp$variable <- as.character(tmp$variable)
tmp$variable <- ordered(nmap(tmp$variable, question_labels), levels=question_labels)
#tmp$variable <- gsub("Q_", "Question ", tmp$variable) # gsub("Q_", "Question ", tmp$variable)

p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy")
print(p)
```

<!-- Field: Q18 -->

Imagine you just found a great journal to target when submitting your next manuscript. You read the Instruction to Authors and discover the journal adheres to the Joint Data Archiving Policy (above). How strongly do you disagree/agree with the following statements?
How strongly do you disagree/agree with the following statements? I am worried that ...

 a.  others might do research I am currently working on  <!-- Field: Q18_1 -->
	b.  others might do research I am planning to do  <!-- Field: Q18_2 -->
	c.  others might find errors in my research  <!-- Field: Q18_3  -->
	d.  others might misinterpret my dataset or use it inappropriately  <!-- Field: Q18_4 -->
	e.  I/we might be bothered with a lot of questions by qualified people  <!-- Field: Q18_5 -->
	f.  I/we might be bothered with a lot of questions by unqualified people  <!-- Field: Q18_6 -->
	g.  I/we might not be able to find the data  <!-- Field: Q18_7 -->
	h.  it might take me/us a lot of time to find the data  <!-- Field: Q18_8 -->
	i.  it might take me/us a lot of time to format or document the data  <!-- Field: Q18_9 -->
	j.  it might take me/us a lot of time to submit the data  <!-- Field:  Q18_10-->
	k.  I might lose intellectual property or commercial opportunities  <!-- Field: Q18_11 -->


```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom

tmp <- melt(d, measure.vars=paste0('Q_10_',1:11 ))
tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("10_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```


<!-- Field: Q19 -->
Same instructions as the previous question: Imagine you just found a great journal to target when submitting your next manuscript. You read the Instruction to Authors and discover the journal adheres to the Joint Data Archiving Policy (above). How strongly do you disagree/agree with the following statements? I am pleased because...

 a.  others will build upon my work more easily  <!-- Field: Q19_1  -->
	b.  I will get more citations  <!-- Field: Q19_2  -->
	c.  I will form more collaborations  <!-- Field: Q19_3  -->
	d.  the contribution will be valued by my promotion or tenure committee  <!-- Field: Q19_4  -->
	c.  the contribution will be valued by my funders  <!-- Field: Q19_5  -->
	d.  I will be able to reuse other work more easily  <!-- Field: Q19_6  -->
	e.  I will be able to reuse other work more often  <!-- Field: Q19_7  -->
	f.  my scientific area will progress more quickly  <!-- Field: Q19_8  -->
	g.  my scientific area will develop better tools and/or training  <!-- Field: Q19_9  -->
	h.  I think it is the right thing to do  <!-- Field: Q19_10  -->


```{r, fig.width=10, fig.height=5, echo=FALSE}

library(ggplot2)
library(reshape2)
source("./src/plotLikert.R")

responses <- c("Strongly Agree","Agree","Somewhat Agree","Somewhat Disagree","Disagree","Strongly Disagree") # response categories from top to bottom

tmp <- melt(d, measure.vars=paste0('Q_11_',1:10 ))

tmp$variable <- letters[gsub("Q_", "", tmp$variable) %>% gsub("11_", "", .) %>% as.integer]
p <- plot_likert(tmp, response='value', var_x='label_PolicyAdoptedAtPublication_space', var_facet="variable", response_order=responses, above_mid="Somewhat Agree", na.label="No response", xlab="% Responses", ylab="JDAP Policy", include.N=FALSE)
p <- p + theme(axis.text.x=element_text(angle=-90, size=8))

print(p)

```



# Discussion

What has happened since

some more: `r citep(c(
bib["2015thank-y"],
bib["anagnostou2015when-da"],
bib["nosek2015scienti"],
bib["stodden2018an-empi"],
bib["budin-ljosne2014data-sh"],
bib["hate2015sweat-s"],
bib["naudet2018data-sh"],
bib["curty2017attitud"],
bib["linek2017data-sh"],
bib["longo2016data-sh"],
bib["berger2016iscbs-i"],
bib["chigusa2017state-o"],
bib["womack2015researc"],
bib["doi:10.1002/asi.23917"],
bib["plos-medicine-editors2016can-dat"],
bib["van-tuyl2016water-w"],
bib["vasilevsky2017reprodu"],
bib["doi:10.1002/asi.23336"],
bib["pearce2011data-sh"],
bib["alsheikh-ali2011public-"],
bib["vines2013mandate"],
bib["roche2014trouble"],
bib["roche2015public-"],
bib["lin2014recomme"],
bib["whitlock2016a-balan"],
bib["naughton-l2016making-"],
bib["teunis2015do-corr"],
bib["fetterman2015the-rep"]
))
`

Response to plos
Future work
With this dataset
Advanced stats
Longer term study
More jdap journals come out



## Future work

Did JDAP-adopting journals start being more eagerly adopted by people who like data archiving, or did the authors in JDAP journals change their minds?


## Limitations

- This study makes no attempt to understand the rigor with which data sharing is encouraged in journals beyond their written policies:  many journals without policies nonetheless expect data sharing and many with written policies fail to enforce them.
- The opinions of corresponding authors with respect to data sharing may not be typical of all authors:  a future study could be done to quantify this.
- Respondents may be reluctant to self-report when they do not share their datasets, particularly as their sense of sharing as a community norm increases, since survey respondents are often reluctant to report engaging in socially undesirable behavior.  This may take the form of non-response, or untruthful responses.
- It will be difficult or impossible to derive causality direction for an association between reported data sharing behaviour and reported perception of data sharing as a community norm.
- By only inviting authors to participate the first time they are listed as corresponding authors within our study scope, the population we are polling will shift gradually over time away from highly-prolific authors.
- Finally, this study only facilitates a relatively short-term look at policy effect:  it will likely take many more years for the effect of these policies to be fully felt.


# Data availability

- IRB
- Survey questions
- Instructions to authors
- Contact corresponding code
- Comparison journals spreadsheet
- R files
- Raw data

# Acknowlegements


# Funding

Heather's postdoc funding.



# Appendix: JDAP Adoption Dates



```{r, fig.width=7, fig.height=5, echo=FALSE}
library(knitr)

journals_in_dataset <- unique(d$Journal)
relevant_jdap_adoption_dates <- subset(jdap_adoption_dates, Journal %in% journals_in_dataset)

table <- subset(relevant_jdap_adoption_dates, policy == "Required")[,c('JournalName','policy_start_str')]
colnames(table) <- c('Journal', 'Adoption Date of JDAP or Equivalent Policy')
rownames(table) <- NULL
kable(table)

```

# Bibliolography

```{r  results="asis", echo=FALSE, message=FALSE}
# bibliography(sorting='nyt')
write.bibtex(file="output_references.bib")
````
